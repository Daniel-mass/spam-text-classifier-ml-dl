{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQ9Tq_KUtoW9",
        "outputId": "2e438c18-8558-494c-f21a-341794645b50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label                                               text\n",
            "0      0  Go until jurong point, crazy.. Available only ...\n",
            "1      0                      Ok lar... Joking wif u oni...\n",
            "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
            "3      0  U dun say so early hor... U c already then say...\n",
            "4      0  Nah I don't think he goes to usf, he lives aro...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"spam.csv\", encoding=\"latin-1\")\n",
        "\n",
        "# Keep only relevant columns and rename them\n",
        "df = df[['v1', 'v2']]\n",
        "df.columns = ['label', 'text']\n",
        "\n",
        "# Convert 'label' to binary (ham = 0, spam = 1)\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Display first few rows\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.columns)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoBB2fWwuZNj",
        "outputId": "af8f824a-259d-4c5d-f8de-9ddf7cb537d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['label', 'text'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.15 keras==2.15\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U9nLbJ9-vkc",
        "outputId": "5705263f-8ca5-4f2c-a046-838f168d4e3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.15 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras==2.15 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (1.26.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (4.25.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (4.12.2)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.7)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (5.5.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Download stopwords if not already downloaded\n",
        "nltk.download(\"stopwords\")\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Function for text cleaning\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r\"<.*?>\", \"\", text)  # Remove HTML tags\n",
        "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))  # Remove punctuation\n",
        "    text = re.sub(r\"\\d+\", \"\", text)  # Remove numbers\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "# Apply text cleaning\n",
        "df[\"cleaned_text\"] = df[\"text\"].apply(clean_text)\n",
        "\n",
        "# Vectorization using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(df[\"cleaned_text\"])\n",
        "\n",
        "# Assign labels\n",
        "y = df[\"label\"]\n",
        "\n",
        "# Print a sample of cleaned text\n",
        "print(df[[\"text\", \"cleaned_text\"]].head())\n",
        "\n",
        "# Print TF-IDF shape\n",
        "print(\"TF-IDF Matrix Shape:\", X.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmPcZK6_ugGm",
        "outputId": "0a3c172a-1674-4ec2-84cc-5b07d3f66f42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  \\\n",
            "0  Go until jurong point, crazy.. Available only ...   \n",
            "1                      Ok lar... Joking wif u oni...   \n",
            "2  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
            "3  U dun say so early hor... U c already then say...   \n",
            "4  Nah I don't think he goes to usf, he lives aro...   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0  go jurong point crazy available bugis n great ...  \n",
            "1                            ok lar joking wif u oni  \n",
            "2  free entry wkly comp win fa cup final tkts st ...  \n",
            "3                u dun say early hor u c already say  \n",
            "4        nah dont think goes usf lives around though  \n",
            "TF-IDF Matrix Shape: (5572, 8448)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convert sparse matrix to dense and show the first 5 rows\n",
        "print(np.round(X.toarray(), 2)[:5])\n",
        "\n",
        "# Print feature names\n",
        "print(vectorizer.get_feature_names_out()[:10])  # First 10 words\n",
        "  # First 10 words\n",
        " # First 10 words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzWr2K7xup-R",
        "outputId": "346466fe-6443-4201-e28c-d3b4c0c129c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "['aa' 'aah' 'aaniye' 'aaooooright' 'aathilove' 'aathiwhere' 'ab' 'abbey'\n",
            " 'abdomen' 'abeg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the sizes\n",
        "print(\"Training set size:\", X_train.shape)\n",
        "print(\"Testing set size:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiwQ8ft-vBR-",
        "outputId": "3ea86dbd-0416-429b-e801-ca6ea8f3718d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: (4457, 8448)\n",
            "Testing set size: (1115, 8448)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Train the Naïve Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = nb_model.predict(X_test)\n"
      ],
      "metadata": {
        "id": "IpfVMDyHvFzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6Yt0dsovLR9",
        "outputId": "392b5c89-d870-4f40-99e2-234354de2da9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.967713004484305\n",
            "\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       965\n",
            "           1       1.00      0.76      0.86       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.98      0.88      0.92      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "bOz3cM74vUXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the text data\n",
        "tokenizer = Tokenizer(num_words=10000)  # Keep the top 10,000 most frequent words\n",
        "tokenizer.fit_on_texts(df[\"cleaned_text\"])\n",
        "\n",
        "# Convert text into sequences\n",
        "X_seq = tokenizer.texts_to_sequences(df[\"cleaned_text\"])\n",
        "\n",
        "# Pad sequences to ensure uniform input length\n",
        "max_len = 100  # Fixed length for all sequences\n",
        "X_padded = pad_sequences(X_seq, maxlen=max_len, padding=\"post\")\n",
        "\n",
        "# Assign labels\n",
        "y = np.array(df[\"label\"])  # Labels: 0 for ham, 1 for spam\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "6yioJYE_vs-o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build LSTM model\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=128, input_length=max_len),\n",
        "    SpatialDropout1D(0.2),  # Dropout to reduce overfitting\n",
        "    LSTM(100, dropout=0.2, recurrent_dropout=0.2),\n",
        "    Dense(1, activation=\"sigmoid\")  # Binary classification (Spam or Ham)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYrsN1_Fv3BL",
        "outputId": "ed262343-4c56-46b7-81e6-c42785ab868e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 128)          1280000   \n",
            "                                                                 \n",
            " spatial_dropout1d (Spatial  (None, 100, 128)          0         \n",
            " Dropout1D)                                                      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 100)               91600     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1371701 (5.23 MB)\n",
            "Trainable params: 1371701 (5.23 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5m-SLqJPv_Vv",
        "outputId": "afd6c212-1193-4c58-a423-45490a015c83"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "140/140 [==============================] - 43s 283ms/step - loss: 0.4116 - accuracy: 0.8620 - val_loss: 0.3951 - val_accuracy: 0.8655\n",
            "Epoch 2/5\n",
            "140/140 [==============================] - 36s 261ms/step - loss: 0.3968 - accuracy: 0.8661 - val_loss: 0.4009 - val_accuracy: 0.8655\n",
            "Epoch 3/5\n",
            "140/140 [==============================] - 37s 262ms/step - loss: 0.3972 - accuracy: 0.8661 - val_loss: 0.3949 - val_accuracy: 0.8655\n",
            "Epoch 4/5\n",
            "140/140 [==============================] - 37s 262ms/step - loss: 0.3955 - accuracy: 0.8661 - val_loss: 0.3970 - val_accuracy: 0.8655\n",
            "Epoch 5/5\n",
            "140/140 [==============================] - 36s 260ms/step - loss: 0.3946 - accuracy: 0.8661 - val_loss: 0.3952 - val_accuracy: 0.8655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlUUMupmxO6v",
        "outputId": "3e0bd9e6-8682-4f6a-9f77-849d1f36f451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "140/140 [==============================] - 37s 263ms/step - loss: 0.3956 - accuracy: 0.8661 - val_loss: 0.3952 - val_accuracy: 0.8655\n",
            "Epoch 2/5\n",
            "140/140 [==============================] - 42s 300ms/step - loss: 0.3947 - accuracy: 0.8661 - val_loss: 0.3952 - val_accuracy: 0.8655\n",
            "Epoch 3/5\n",
            "140/140 [==============================] - 37s 261ms/step - loss: 0.3958 - accuracy: 0.8661 - val_loss: 0.3954 - val_accuracy: 0.8655\n",
            "Epoch 4/5\n",
            "140/140 [==============================] - 35s 253ms/step - loss: 0.3945 - accuracy: 0.8661 - val_loss: 0.3952 - val_accuracy: 0.8655\n",
            "Epoch 5/5\n",
            "140/140 [==============================] - 37s 264ms/step - loss: 0.3959 - accuracy: 0.8661 - val_loss: 0.3949 - val_accuracy: 0.8655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfoOyynbyFAP",
        "outputId": "75f25cb0-5b47-428c-ce30-b114d45be6b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35/35 [==============================] - 2s 63ms/step - loss: 0.3949 - accuracy: 0.8655\n",
            "Test Accuracy: 0.8655\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0]}  # Alpha is the smoothing parameter\n",
        "\n",
        "# Perform grid search\n",
        "grid_search = GridSearchCV(MultinomialNB(), param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Best model and accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-k2C-9Q30ke0",
        "outputId": "98fad7dc-09fa-4d77-f3f9-da9025f4befd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'alpha': 0.1}\n",
            "Best Accuracy: 0.8236432586955755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import GRU\n",
        "\n",
        "# Replace LSTM with GRU\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=10000, output_dim=128, input_length=max_len),\n",
        "    SpatialDropout1D(0.2),\n",
        "    GRU(100, dropout=0.2, recurrent_dropout=0.2),  # GRU instead of LSTM\n",
        "    Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test), verbose=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UVBABXI902Jd",
        "outputId": "b0cfb6b0-f382-4f63-be2e-daa8ce45b319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "140/140 [==============================] - 50s 327ms/step - loss: 0.4099 - accuracy: 0.8620 - val_loss: 0.3950 - val_accuracy: 0.8655\n",
            "Epoch 2/10\n",
            "140/140 [==============================] - 37s 262ms/step - loss: 0.3984 - accuracy: 0.8661 - val_loss: 0.3949 - val_accuracy: 0.8655\n",
            "Epoch 3/10\n",
            "140/140 [==============================] - 35s 252ms/step - loss: 0.3957 - accuracy: 0.8661 - val_loss: 0.4014 - val_accuracy: 0.8655\n",
            "Epoch 4/10\n",
            "140/140 [==============================] - 35s 253ms/step - loss: 0.3967 - accuracy: 0.8661 - val_loss: 0.3953 - val_accuracy: 0.8655\n",
            "Epoch 5/10\n",
            "140/140 [==============================] - 34s 242ms/step - loss: 0.3953 - accuracy: 0.8661 - val_loss: 0.3949 - val_accuracy: 0.8655\n",
            "Epoch 6/10\n",
            "140/140 [==============================] - 35s 253ms/step - loss: 0.3963 - accuracy: 0.8661 - val_loss: 0.3971 - val_accuracy: 0.8655\n",
            "Epoch 7/10\n",
            "140/140 [==============================] - 35s 252ms/step - loss: 0.3964 - accuracy: 0.8661 - val_loss: 0.3950 - val_accuracy: 0.8655\n",
            "Epoch 8/10\n",
            "140/140 [==============================] - 34s 242ms/step - loss: 0.3955 - accuracy: 0.8661 - val_loss: 0.3949 - val_accuracy: 0.8655\n",
            "Epoch 9/10\n",
            "140/140 [==============================] - 35s 252ms/step - loss: 0.3949 - accuracy: 0.8661 - val_loss: 0.3953 - val_accuracy: 0.8655\n",
            "Epoch 10/10\n",
            "140/140 [==============================] - 35s 254ms/step - loss: 0.3961 - accuracy: 0.8661 - val_loss: 0.3950 - val_accuracy: 0.8655\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79d4d4731dd0>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Daniel-mass/spam-text-classifier-ml-dl.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyKBhtMDAWJj",
        "outputId": "95027b0d-9d1a-4b32-985f-f3ddadd9d691"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'spam-text-classifier-ml-dl'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd spam-text-classifier-ml-dl\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C69Zuk2YAcRR",
        "outputId": "4a060d65-6cbf-4510-b4e5-23b3cb88975c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/spam-text-classifier-ml-dl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.name \"Danie-mass\""
      ],
      "metadata": {
        "id": "zchUMD04Algz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"danieldenision@gmail.com\""
      ],
      "metadata": {
        "id": "4eCXJKiMAqjp"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, getpass, subprocess, shlex\n",
        "token = getpass.getpass('Paste your GitHub token (input hidden): ')\n",
        "os.environ['GITHUB_TOKEN'] = token\n",
        "\n",
        "# Set remote URL to include the token (only in memory for this runtime)\n",
        "remote_url = \"https://{}@github.com/daniel-mass/spam-text-classifier-ml-dl.git\".format(os.environ['GITHUB_TOKEN'])\n",
        "subprocess.run(shlex.split(f'git remote set-url origin \"{remote_url}\"'), check=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RsmdHw28BAzB",
        "outputId": "241f537a-b191-4d4a-f0c9-68ea93cb1cb9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your GitHub token (input hidden): ··········\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['git', 'remote', 'set-url', 'origin', 'https://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@github.com/daniel-mass/spam-text-classifier-ml-dl.git'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add -A"
      ],
      "metadata": {
        "id": "Ip7_-u7lCwDh"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Initial push from Colab\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0AzhTOVCx9r",
        "outputId": "1819d4ff-7abe-4ed1-98af-1f02565af66d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin HEAD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DZaJqr7C3Lt",
        "outputId": "18bcf8a3-bb92-4cdb-b631-f90db6df5049"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M41MVrHgDqHq",
        "outputId": "6320d076-3357-4ce1-b56f-61a922d84c49"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/spam-text-classifier-ml-dl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Qe1fUNYDvTM",
        "outputId": "fa2a323d-66db-47f7-9fd3-938d3e6fc32d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git status\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_KLJdeMD9c7",
        "outputId": "54f4d04d-5ed3-4b39-adae-1ec93fd2854e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add README.md"
      ],
      "metadata": {
        "id": "utO9ilRBEFn0"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m \"Add README\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmmI8k1ZEL9-",
        "outputId": "2653cd28-aff3-41cf-e9b9-8eac211fbd38"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin HEAD"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrJA5R83EPTy",
        "outputId": "c9ff5a8d-9a45-4c06-9d44-4acf99f42b09"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To https://github.com/daniel-mass/spam-text-classifier-ml-dl.git\n",
            " \u001b[31m! [rejected]       \u001b[m HEAD -> main (fetch first)\n",
            "\u001b[31merror: failed to push some refs to 'https://github.com/daniel-mass/spam-text-classifier-ml-dl.git'\n",
            "\u001b[m\u001b[33mhint: Updates were rejected because the remote contains work that you do\u001b[m\n",
            "\u001b[33mhint: not have locally. This is usually caused by another repository pushing\u001b[m\n",
            "\u001b[33mhint: to the same ref. You may want to first integrate the remote changes\u001b[m\n",
            "\u001b[33mhint: (e.g., 'git pull ...') before pushing again.\u001b[m\n",
            "\u001b[33mhint: See the 'Note about fast-forwards' in 'git push --help' for details.\u001b[m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull --rebase origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZvvNaDvEcdI",
        "outputId": "3bb6dd25-a253-4257-952d-42d38c8ba14a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects:  20% (1/5)\u001b[K\rremote: Counting objects:  40% (2/5)\u001b[K\rremote: Counting objects:  60% (3/5)\u001b[K\rremote: Counting objects:  80% (4/5)\u001b[K\rremote: Counting objects: 100% (5/5)\u001b[K\rremote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects:  33% (1/3)\rUnpacking objects:  66% (2/3)\rUnpacking objects: 100% (3/3)\rUnpacking objects: 100% (3/3), 1.67 KiB | 1.67 MiB/s, done.\n",
            "From https://github.com/daniel-mass/spam-text-classifier-ml-dl\n",
            " * branch            main       -> FETCH_HEAD\n",
            "   2a58bb5..c9f7eb7  main       -> origin/main\n",
            "Updating 2a58bb5..c9f7eb7\n",
            "Fast-forward\n",
            " README.md | 53 \u001b[32m+++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 51 insertions(+), 2 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git push origin main\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgjgdRQaEqAj",
        "outputId": "71ebdaa7-bc34-4eee-8191-e10a28e51af5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Everything up-to-date\n"
          ]
        }
      ]
    }
  ]
}